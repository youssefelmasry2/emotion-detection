first model we used a simple cnn model   ''model = tf.keras.models.Sequential([
                                               tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
                                                tf.keras.layers.MaxPooling2D((2, 2)),
                                                tf.keras.layers.Flatten(),
                                                tf.keras.layers.Dense(128, activation='relu'),
                                                tf.keras.layers.Dense(7, activation='softmax')  # 7 classes for the 7 emotions
                                                                                                                                ])''
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_generator, epochs=10, validation_data=val_generator)
test_loss, test_acc = model.evaluate(test_generator)
print(f'Test Accuracy: {test_acc}')
first model result was [0.4304820]

trying to implent early stopping function and see result on model 2
the accuracy increased in model 2 [0.4661465585231781]


trying to make model3 more complexe by adding layers in model 3
 tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
 accuracy increased [0.530509889125824]

 trying to make model4 more complexe by adding layers
  tf.keras.layers.MaxPooling2D((2, 2))
  tf.keras.layers.Dense(256, activation='relu'),
  tf.keras.layers.Dropout(0.5),  # Add dropout for regularization
  accuracy decreased [0.5176929235458374]



  in model 5:
  removed dense(256) layer
  accuracy increased [0.5500139594078064]

  in model 6:
  added more data augmention
   rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    accuracy decreased [0.44524937868118286]

    in model 7:
    removed previous data augmention and removed zoom range=0.2
    accuracy increased [0.5628308653831482]
    
    in model 8:
    add 15 epochs instead of 10
    accuracy increased [0.568682074546814]

    in model 9:
    added 20 epochs instead of 15
    accuracy increased[0.5834494233131409]

    in model 10:
    trying 30 epochs instead of 20
    code stoped at 12 accuracy decreased [0.5580942034721375]

    in model 11:
    trying 25 epochs
    code stoped at 16 and accuracy decreased[0.561437726020813]
     
    in model 12:
    returned to 20 epochs changed erarly stop function to monitor accuracy instead of val_loss
    accuracy decreased [0.5583727955818176]

    model 13:
    trying batch size 64 instead of 32
    same result

    model 14:
    increainsg patience to 7 
    accuracy [0.5817776322364807] 

    model 15:
    batch size 128
    accuracy [0.57704097032547]

    model 16
    added 2 more layers
    accuracy [0.6071329116821289]


    model 17
    learning rate 0.0001
    epochs 100
    early stop patience 10

    accuracy [0.6132627725601196]

    model 18
    epoch 200
    batch 128
    accuracy [0.6213430166244507]

    model 19
    extract from ck+ dataset disgust photos to balance classes
    we put half in trainning set and other in val
    changing to 1 channel gray scale
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(516, activation='relu'),

    accuracy [0.6188353300094604]
    
    we go with model 18 final best result
    
    

 


